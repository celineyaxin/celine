# 整理一下新的投诉的样本（确认是否需要补充一些非放贷商家）
## 1. financialmerchant.py **处理后的商家列表.csv**
* 删除已经筛选出来的金融类商家
* 删除已经筛选的旅游类商家
* 根据公司名称可以判别类别的删除

## 2. merchant_delete.py **处理后的商家列表.xlsx**
* 在筛选的过程中通过名称剔除

# 对投诉文本分类做异质性 
## 全文本生成**classify_sample.csv**
## 1. privacy_classify.py：是否依赖个人信息的类别分类
* 依赖/不依赖个人信息实施的欺诈行为
* 根据文件**fruad_privacy_serious.xlsx**编著结果进行分类

## 2.business_classify.py
* 根据投诉的文本具体判断业务的类型（投诉人具体用的是哪个业务）
### without2.py
* 类别2是信用卡业务可以单独处理
### check3.py
* 原始文件对于3的类别定义并不太清楚
* 针对3的类别添加了车贷/教育分期等更加清晰的条件
* 已经筛选出来明确不涉及这些业务的类型不参与分类
* **vip/会员/征信报告 也可以通过关键词处理**

## 欺诈样本分类 
### 生成欺诈的原始分类文件：classify_fin_processed.csv
* 生成**sample_fraud.csv**是从欺诈的文本中随机抽取5000条，但是没有根据投诉内容删除重复值，并且没有保留生成这个文件的代码。对于分类的质量做了一些处理
### sample_check.py
* 1. 首先复核一下提取出来的excel文件中投诉内容是否都是欺诈样本
* 2. 删除重复值后不足5000条要在未提取的投诉中随机抽取补足
* 3. 保证没有重复值，补充生成**classify_fin.csv**

### fin_sample_check.py
* classify_fin.csv中包含的360的投诉太多了，现在需要删除一些
* 筛选出许多需要删除的商家，控制他们的投诉数量
* 从剩余的投诉中筛选更多丰富的商家信息补充进来 **classify_fin_processed.csv**

## 3. fraud_classify.py
* 我们需要把样本分为个人信息依赖相关的欺诈与不相关的欺诈
* 这中间会有一些难以判断的模糊部分（如隐藏费用，高利贷）
* 因此在分类过程中我们把明确利用信息与完全不利用信息两个类别
* 并且筛选出对应的子分类，方便做进一步的分类 
* 根据**合并结果.xlsx**标注内容进行分类

## 4. BertTrain.py
* 根据fraud_classify.py中筛选出来的类别进行大样本多分类
* 多类别调整性能
### 类别不均衡影响分类效果，我们主要有以下调整思路
* 首先，我们通过调整合并部分类别，针对非常少数量类别的合并
* 其次，我们通过增加样本标记补充部分少样本的类别
* 之后，我们也具体了解了一些样本数量调整方法的原理以及可行性分析
（1）通过上下采样平衡样本**class_balance.py**其中过采样通过向量随机组合构件新的样本不可信
（2）通过样本增强：语句的删除，增加，同义词替换等方式增加样本数量
（3）批量归一
（4）通过错误标记样本进行样本增强，筛选出预测错误的样本然后用大语言模型生成类似表达，可以查看效果
训练好的模型输出**recognition_error.py**
训练过程中输出**BertTrainerror.py**
（5）直接对小样本通过大语言模型生成相似样本**similar_extend.py**可以完成部分数量的补充
* 另外，我们也尝试了通过保持多样本是小样本比例的情况去完成样本的分类，提升了模型的效果**target_ratio.py** 得到文件**balanced_data.xlsx**，基于该文件进行分类
* 增加样本标记去补充

### sample_add.py
* 排除掉已经筛选出来的投诉内容
* 按照年份/商家均匀抽取投诉内容3000条进行补充分类 **sample_add.csv**
* 补充部分样本**sample_add_2.py**生成**supplement_fraud_sample_5000_2.xlsx**
* 补充部分样本**sample_add_3.py**生成**fraud_sample_5000.xlsx**

### sample_add_classify.py
* 对以上样本进行分类

添加训练样本能够增加模型的判别能力，会议上大模型方向的学者验证如果20%人工标注用于大模型的学习，样本内的标注效果能够达到100%。因此我们随机抽取部分样本用于训练
### model_learn.py
* 通过随机抽取样本获得用于学习的样本**auto_sampled_complaints.xlsx**
### learn_classify.py**
基于人工标注的样本上传给模型一个学习的样本，重新标注剩余样本

# 5. fraud_privacy.py
* 筛选出既是欺诈又是隐私的投诉内容

# 6. delete_clear.py
* 在欺诈投诉中剔除掉明示投诉的内容

# 是否根据投诉文本整理提取投诉人的异质性
* 1. 隐私保护的意识
* 2. 是否是弱势群体

# 通过大语言模型进行分类的标准方法
## 1. text_sample_classify.py
* 根据命令将文本分类成是否隐私相关的投诉
* 根据命令将文本分类成是否欺诈相关的投诉
* 根据金融欺诈的业务类型筛选出一些典型的类型进行分类
高利贷与超高利息 砍头息与虚假到账 隐藏费用与捆绑销售 暴力催收与骚扰 虚假合同与阴阳条款 强制放贷与未授权操作 虚假宣传与诱导贷款 变相收费与商品捆绑

A1 强制放款
A2 高利贷
A3 砍头息
A4 阴阳合同
A5 强制增值服务
A6 虚假宣传
A7 暴力催收
A8 提前还款受限
A9 身份盗用
A10 违规服务费
A11 平台异常
A12 隐私侵犯

![alt text](image.png)
![alt text](image-1.png)

## 2. double_check.py
* 根据上面生成的分类换模型重新生成分类标准
* 生成一列比对生成的结果是否一致（一致更好判断）

# 数据处理随机分成三个训练文件
## random_allocation.py
* 随机分配生成三个文件train/dev/test

## random_allocation_complicate.py
* 针对复杂多分类任务的分类
* 在数据处理的过程中因为要尽可能覆盖到更多类型的数据，这样进行分类更准确
* subclass_allocation.py 我们使用子分类进行切分，但是保持母分类的tag


# 处理裁判文书的数据
由于数据过大，我们现在硬盘中获取原始文件
## decompress.py
* 由于文件过大，解压速度太慢，通过解压软件中途断开会损失源文件
* 代码解压能够提升解压的速度

## 整理数据库
这个数据库中有一些月份切割的混乱的情况，先找到哪些文件夹需要
### check_month.py
* 确认文件中是否都是这个月的数据
### check_month_folder.py
* 文件夹中循环确认每个数据是否只包含这个月
### summary.py
* 由于文件比较大只能在python里面读取

## 提取企业对应的司法条目
### filter_judicialrecods.py
* 根据企业的的名称通过案件名称去搜索，获取对应的企业名称的司法记录
* 遍历每个文件夹去匹配然后提取对应的条目写入到csv中
* 注意解决前后两批文件的列数不一样的问题
* 由于记录条目比较多我们先提取信息生成对应的csv再做后续处理

### date_reclassify.py 
* 对于年份数据混乱的问题我们对于提取出来的数据重新分类整理
* 主要覆盖范围是2021.10及之后
* 条目可以用于核对数据的完整性

### filter_condition.py（2018.8.1-2021.7.31）
* 提取出来2021年8月法案颁布之前有过行政处罚记录的企业
* 以及处罚的条目获取企业-年月-次数的面板数据
* 2018.8.1-2021.7.31：412
* 2016.8.1-2021.7.31：435

### filter_reason.py
* 提取案由信息，判断一下都有哪些案件类型，最好找到和隐私相关度高的一些类型

### filter_privacy.py
* 在原始文件中根据案例全文根据关键词检索是否包含隐私/个人信息等相关词汇
* 筛选出样本企业案例中包含隐私/个人信息的数据条目用于后续筛选

### 处理2018的数据
* filter_judicialrecods.py:提取2018年的数据写入tempfiles文件夹
* filter_condition.py:提取时间范围内的纠纷企业（2018.8.1-2021.7.31）
* filter_privacy.py：隐私相关案件我先处理一下然后再提取
* 受过更多次数影响纠纷的企业更容易有效果
* 处理2017/2016指定时间段